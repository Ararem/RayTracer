using RayTracer.Core.Debugging;
using RayTracer.Core.Scenes;
using SixLabors.ImageSharp;
using SixLabors.ImageSharp.PixelFormats;
using System.Numerics;
using System.Runtime.CompilerServices;

namespace RayTracer.Core.Graphics;

/// <summary>
///  Class for rendering a <see cref="Scene"/>, using it's <see cref="Scenes.Scene.Camera"/>.
/// </summary>
/// <remarks>
///  Uses the rays generated by the <see cref="Camera"/>, and objects in the <see cref="Scene"/> to create the output image
/// </remarks>
public sealed class AsyncRenderJob
{
	/// <summary>
	///  Creates an async render job for a <paramref name="scene"/>, with configurable <paramref name="renderOptions"/>
	/// </summary>
	/// <param name="scene">The scene containing the objects and camera for the render</param>
	/// <param name="renderOptions">
	///  Record containing options that affect how the resulting image is produced, such as resolution, multisample count or debug
	///  visualisations
	/// </param>
	public AsyncRenderJob(Scene scene, RenderOptions renderOptions)
	{
		Scene                = scene;
		Buffer               = new Image<Rgb24>(renderOptions.Width, renderOptions.Height);
		RenderOptions        = renderOptions;
		taskCompletionSource = new TaskCompletionSource<Image<Rgb24>>(this);
		Task.Run(RenderInternal);
	}

	private void RenderInternal()
	{
		(_, Camera cam, SceneObject[] objects) = Scene;
		Image<Rgb24> image = new(RenderOptions.Width, RenderOptions.Height);
		for (int x = 0; x < RenderOptions.Width; x++)
		{
			for (int y = 0; y < RenderOptions.Height; y++)
			{
				//Get the view ray from the camera
				//We have to flip the y- value because the camera expects y=0 to be the bottom
				//But the image expects it to be at the top
				Ray r = cam.GetRay((float)x / RenderOptions.Width, (float)(RenderOptions.Height - y - 1) / RenderOptions.Height);

				#if DEBUG

				//Check camera view ray magnitude is 1
				if (Math.Abs(r.Direction.LengthSquared() - 1f) > 0.001f)
					GraphicsError.RecordError(GraphicsErrorType.RayDirectionWrongMagnitude, cam);
				#endif

				//Sky colour
				float t   = 0.5f * (r.Direction.Y + 1);
				Rgb24 col = new(ToByte((1 - t) + (0.5f * t)), ToByte((1 - t) + (0.7f * t)), ToByte((1 - t) + (1f * t)));

				//Loop over the objects to see if we hit anything
				foreach (SceneObject sceneObject in objects)
				{
					//Account for the offset of the object
					Ray correctedRay = new(r.Origin - sceneObject.Position, r.Direction);
					//TODO: Object rotation
					if (sceneObject.Hittable.TryHit(correctedRay, RenderOptions.KMin, RenderOptions.KMax) is { } hit)
					{
						#if DEBUG
						//Check that the normal magnitude is approx 1 unit
						//Don't have to sqrt it because 1 squared is 1
						if (Math.Abs(hit.Normal.LengthSquared() - 1f) > 0.001f)
							GraphicsError.RecordError(GraphicsErrorType.NormalsWrongMagnitude, sceneObject);

						//Check if the K value is in the correct range
						if ((hit.K < RenderOptions.KMin) || (hit.K > RenderOptions.KMax))
							GraphicsError.RecordError(GraphicsErrorType.KValueNotInRange, sceneObject);

						#endif
						switch (RenderOptions.DebugVisualisation)
						{
							case GraphicsDebugVisualisation.Normals:
							{
								//Convert normal values [-1..1] to [0..1]
								Vector3 n = (hit.Normal + Vector3.One) / 2f;
								col = new Rgb24(ToByte(n.X), ToByte(n.Y), ToByte(n.Z));
								break;
							}
							case GraphicsDebugVisualisation.FaceDirection:
							{
								//Convert normal values [-1..1] to [0..1]
								col = hit.OutsideFace ? new Rgb24(0, 255, 0) : new Rgb24(255, 0, 0);
								break;
							}
							//Render the object normally
							case GraphicsDebugVisualisation.None:
							default:
								col = new Rgb24(255, ToByte(hit.K / 5f), 0);
								break;
						}
					}
				}

				image[x, y] = col;
			}
		}

		//Notify that the render is complete
		taskCompletionSource.SetResult(image);
	}

	/// <summary>
	///  Converts a float in the range [0..1] to a byte ([0..255])
	/// </summary>
	public static byte ToByte(float f) => (byte)(255f * f);

#region State

	/// <summary>
	///  The scene that is being rendered
	/// </summary>
	public Scene Scene { get; }

	/// <summary>
	///  Image buffer for the output image
	/// </summary>
	public Image<Rgb24> Buffer { get; }

	/// <summary>
	///  Options to modify how the image is rendered
	/// </summary>
	public RenderOptions RenderOptions { get; }

#endregion

#region Task-like awaitable implementation

	/// <summary>
	///  Whether this render job has completed rendering
	/// </summary>
	public bool RenderCompleted => taskCompletionSource.Task.IsCompleted;

	/// <summary>
	///  Internal object used for task-like awaiting
	/// </summary>
	private readonly TaskCompletionSource<Image<Rgb24>> taskCompletionSource;

	/// <summary>
	///  Gets the task awaiter for this instance
	/// </summary>
	public TaskAwaiter<Image<Rgb24>> GetAwaiter() => taskCompletionSource.Task.GetAwaiter();

#endregion
}